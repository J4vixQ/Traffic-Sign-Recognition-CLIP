{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb0cefa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from transformers import CLIPModel, CLIPProcessor\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MODEL_NAME = \"openai/clip-vit-base-patch32\"\n",
    "\n",
    "model = CLIPModel.from_pretrained(MODEL_NAME).to(DEVICE)\n",
    "processor = CLIPProcessor.from_pretrained(MODEL_NAME)\n",
    "\n",
    "with open(\"prompt_cn.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    prompt_data = json.load(f)\n",
    "\n",
    "CATEGORIES = list(prompt_data.keys())\n",
    "PROMPT_VARIATIONS = list(prompt_data.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4201caa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_text_features(variations: list, device: str):\n",
    "    \"\"\"\n",
    "    把所有 prompt 一次性编码为归一化后的特征向量。\n",
    "    返回：\n",
    "      text_features: Tensor[num_prompts, dim]\n",
    "      prompt_to_cat: List[num_prompts]，映射到类别索引\n",
    "    \"\"\"\n",
    "    all_prompts = [p for vs in variations for p in vs]\n",
    "    prompt_to_cat = []\n",
    "    for idx, vs in enumerate(variations):\n",
    "        prompt_to_cat += [idx] * len(vs)\n",
    "\n",
    "    inputs = processor(\n",
    "        text=all_prompts,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        feats = model.get_text_features(**inputs)\n",
    "        feats = feats / feats.norm(dim=-1, keepdim=True)\n",
    "    return feats, prompt_to_cat\n",
    "\n",
    "# 执行一次\n",
    "TEXT_FEATURES, PROMPT_TO_CAT = init_text_features(PROMPT_VARIATIONS, DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42c7eed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(img: Image.Image, \n",
    "                   text_feats: torch.Tensor, \n",
    "                   prompt_to_cat: list, \n",
    "                   top_k: int = 5, \n",
    "                   return_all: bool = False):\n",
    "    inputs = processor(images=img, return_tensors=\"pt\", padding=True).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        img_feat = model.get_image_features(**inputs)\n",
    "        img_feat = img_feat / img_feat.norm(dim=-1, keepdim=True)\n",
    "        logits = model.logit_scale.exp() * img_feat @ text_feats.T\n",
    "        probs = logits.softmax(dim=-1)[0].cpu().numpy()\n",
    "\n",
    "    # 聚合到类别\n",
    "    cat_probs = np.zeros(len(CATEGORIES))\n",
    "    for i, p in enumerate(probs):\n",
    "        cat_probs[prompt_to_cat[i]] += p\n",
    "    cat_probs /= cat_probs.sum()\n",
    "\n",
    "    if return_all:\n",
    "        idxs = np.argsort(-cat_probs)\n",
    "    else:\n",
    "        idxs = np.argpartition(cat_probs, -top_k)[-top_k:]\n",
    "        idxs = idxs[np.argsort(-cat_probs[idxs])]\n",
    "\n",
    "    return [(CATEGORIES[i], float(cat_probs[i])) for i in idxs]\n",
    "\n",
    "\n",
    "def classify_batch(imgs: list, **kwargs) -> list:\n",
    "    return [ classify_image(img, TEXT_FEATURES, PROMPT_TO_CAT, **kwargs) for img in imgs ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9c87fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_directory(directory: str,\n",
    "                       ground_truth: dict,\n",
    "                       batch_size: int = 16,\n",
    "                       top_k: int = 5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    return every image's top-5 predictions (labels and probabilities) and rank.\n",
    "    \"\"\"\n",
    "    files = [f for f in os.listdir(directory) if f.lower().endswith((\".png\"))]\n",
    "    rows = []\n",
    "    for i in range(0, len(files), batch_size):\n",
    "        batch = files[i:i+batch_size]\n",
    "        imgs  = []\n",
    "        for fn in batch:\n",
    "            img = Image.open(os.path.join(directory, fn)).convert(\"RGB\")\n",
    "            imgs.append(img)\n",
    "\n",
    "        preds_batch = classify_batch(imgs, top_k=top_k, return_all=True)\n",
    "        for fn, preds in zip(batch, preds_batch):\n",
    "            true = ground_truth.get(fn, \"Unknown\")\n",
    "            # extract top-5 predictions\n",
    "            labels = [x[0] for x in preds[:5]]\n",
    "            scores = [x[1] for x in preds[:5]]\n",
    "            if len(labels) < 5:\n",
    "                labels += [\"\"] * (5 - len(labels))\n",
    "                scores += [0.0] * (5 - len(scores))\n",
    "            row = {\n",
    "                \"Image\": fn,\n",
    "                \"True Label\": true\n",
    "            }\n",
    "            # include top-5 predictions (labels and probabilities)\n",
    "            for i in range(5):\n",
    "                row[f\"Top{i+1}_Label\"] = labels[i]\n",
    "                row[f\"Top{i+1}_Prob\"] = scores[i]\n",
    "            # calculate rank\n",
    "            found = -1\n",
    "            for k in range(1, 6):\n",
    "                if row[f\"Top{k}_Label\"] == true:\n",
    "                    found = k\n",
    "                    break\n",
    "            row[\"Rank\"] = found\n",
    "            rows.append(row)\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c28e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>True Label</th>\n",
       "      <th>Top1_Label</th>\n",
       "      <th>Top1_Prob</th>\n",
       "      <th>Top2_Label</th>\n",
       "      <th>Top2_Prob</th>\n",
       "      <th>Top3_Label</th>\n",
       "      <th>Top3_Prob</th>\n",
       "      <th>Top4_Label</th>\n",
       "      <th>Top4_Prob</th>\n",
       "      <th>Top5_Label</th>\n",
       "      <th>Top5_Prob</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>animal_crossing_0.png</td>\n",
       "      <td>animal crossing</td>\n",
       "      <td>animal crossing</td>\n",
       "      <td>0.153623</td>\n",
       "      <td>round about</td>\n",
       "      <td>0.145946</td>\n",
       "      <td>stop</td>\n",
       "      <td>0.085567</td>\n",
       "      <td>give way</td>\n",
       "      <td>0.059918</td>\n",
       "      <td>steep descent</td>\n",
       "      <td>0.054768</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>animal_crossing_1.png</td>\n",
       "      <td>animal crossing</td>\n",
       "      <td>steep descent</td>\n",
       "      <td>0.159773</td>\n",
       "      <td>steep ascent</td>\n",
       "      <td>0.130587</td>\n",
       "      <td>pedestrian crossing</td>\n",
       "      <td>0.081538</td>\n",
       "      <td>cycle crossing</td>\n",
       "      <td>0.067190</td>\n",
       "      <td>road work ahead</td>\n",
       "      <td>0.064027</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>animal_crossing_2.png</td>\n",
       "      <td>animal crossing</td>\n",
       "      <td>steep descent</td>\n",
       "      <td>0.129220</td>\n",
       "      <td>no overtaking</td>\n",
       "      <td>0.094270</td>\n",
       "      <td>animal crossing</td>\n",
       "      <td>0.075137</td>\n",
       "      <td>steep ascent</td>\n",
       "      <td>0.073996</td>\n",
       "      <td>narrow roads ahead</td>\n",
       "      <td>0.057431</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>animal_crossing_3.png</td>\n",
       "      <td>animal crossing</td>\n",
       "      <td>animal crossing</td>\n",
       "      <td>0.439263</td>\n",
       "      <td>round about</td>\n",
       "      <td>0.124138</td>\n",
       "      <td>slippery road</td>\n",
       "      <td>0.038707</td>\n",
       "      <td>no overtaking</td>\n",
       "      <td>0.033730</td>\n",
       "      <td>bumpy road</td>\n",
       "      <td>0.033481</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>animal_crossing_4.png</td>\n",
       "      <td>animal crossing</td>\n",
       "      <td>steep descent</td>\n",
       "      <td>0.127017</td>\n",
       "      <td>slippery road</td>\n",
       "      <td>0.118197</td>\n",
       "      <td>steep ascent</td>\n",
       "      <td>0.110650</td>\n",
       "      <td>pedestrian crossing</td>\n",
       "      <td>0.077748</td>\n",
       "      <td>bumpy road</td>\n",
       "      <td>0.058492</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Image       True Label       Top1_Label  Top1_Prob  \\\n",
       "0  animal_crossing_0.png  animal crossing  animal crossing   0.153623   \n",
       "1  animal_crossing_1.png  animal crossing    steep descent   0.159773   \n",
       "2  animal_crossing_2.png  animal crossing    steep descent   0.129220   \n",
       "3  animal_crossing_3.png  animal crossing  animal crossing   0.439263   \n",
       "4  animal_crossing_4.png  animal crossing    steep descent   0.127017   \n",
       "\n",
       "      Top2_Label  Top2_Prob           Top3_Label  Top3_Prob  \\\n",
       "0    round about   0.145946                 stop   0.085567   \n",
       "1   steep ascent   0.130587  pedestrian crossing   0.081538   \n",
       "2  no overtaking   0.094270      animal crossing   0.075137   \n",
       "3    round about   0.124138        slippery road   0.038707   \n",
       "4  slippery road   0.118197         steep ascent   0.110650   \n",
       "\n",
       "            Top4_Label  Top4_Prob          Top5_Label  Top5_Prob  Rank  \n",
       "0             give way   0.059918       steep descent   0.054768     1  \n",
       "1       cycle crossing   0.067190     road work ahead   0.064027    -1  \n",
       "2         steep ascent   0.073996  narrow roads ahead   0.057431     3  \n",
       "3        no overtaking   0.033730          bumpy road   0.033481     1  \n",
       "4  pedestrian crossing   0.077748          bumpy road   0.058492    -1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"ground_truth_cn.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    gt = json.load(f)\n",
    "\n",
    "# Per image predictions (labels and probabilities) and rank\n",
    "df_results = evaluate_directory(\"cn\", ground_truth=gt, batch_size=16, top_k=5)\n",
    "df_results.to_csv(\"rs/zeroshotRS/per_image_top5.csv\", index=False)\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dc5894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.450893</td>\n",
       "      <td>0.470479</td>\n",
       "      <td>0.439722</td>\n",
       "      <td>0.411967</td>\n",
       "      <td>448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Macro Precision  Macro Recall  Macro F1  Support\n",
       "0  0.450893         0.470479      0.439722  0.411967      448"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overall macro metrics\n",
    "with open(\"ground_truth_cn.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    gt = json.load(f)\n",
    "\n",
    "\n",
    "label_names = sorted(set(gt.values()))\n",
    "label2id = {name: idx for idx, name in enumerate(label_names)}\n",
    "id2label = {idx: name for name, idx in label2id.items()}\n",
    "NUM_CLASSES = len(label2id)\n",
    "\n",
    "y_true = df_results[\"True Label\"].values\n",
    "y_pred = df_results[\"Top1_Label\"].values\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "p, r, f1, s = precision_recall_fscore_support(\n",
    "    y_true, y_pred, labels=label_names, average='macro', zero_division=0)\n",
    "\n",
    "overall_metrics = {\n",
    "    \"Accuracy\": [acc],\n",
    "    \"Macro Precision\": [p],\n",
    "    \"Macro Recall\": [r],\n",
    "    \"Macro F1\": [f1],\n",
    "    \"Support\": [len(y_true)]\n",
    "}\n",
    "df_overall_metrics = pd.DataFrame(overall_metrics)\n",
    "df_overall_metrics.to_csv(\"rs/zeroshotRS/overall_macro_metrics.csv\", index=False)\n",
    "\n",
    "df_overall_metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f54a952f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>animal crossing</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bumpy road</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cross road</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cycle crossing</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dip</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Class  Precision  Recall        F1  Support\n",
       "0  animal crossing   0.428571     0.3  0.352941       10\n",
       "1       bumpy road   0.000000     0.0  0.000000       10\n",
       "2       cross road   1.000000     0.4  0.571429       10\n",
       "3   cycle crossing   0.666667     1.0  0.800000       20\n",
       "4              dip   0.000000     0.0  0.000000       10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Per-class macro metrics\n",
    "y_true = df_results[\"True Label\"].values\n",
    "y_pred = df_results[\"Top1_Label\"].values\n",
    "\n",
    "p_c, r_c, f1_c, s_c = precision_recall_fscore_support(\n",
    "    y_true, y_pred, labels=label_names, average=None, zero_division=0)\n",
    "\n",
    "df_per_class_metrics = pd.DataFrame({\n",
    "    \"Class\": label_names,\n",
    "    \"Precision\": p_c,\n",
    "    \"Recall\": r_c,\n",
    "    \"F1\": f1_c,\n",
    "    \"Support\": s_c\n",
    "})\n",
    "\n",
    "df_per_class_metrics.to_csv(\"rs/zeroshotRS/per_class_macro_metrics.csv\", index=False)\n",
    "df_per_class_metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a392bdb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top-K</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top-1</td>\n",
       "      <td>0.450893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Top-2</td>\n",
       "      <td>0.649554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Top-3</td>\n",
       "      <td>0.758929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Top-4</td>\n",
       "      <td>0.808036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Top-5</td>\n",
       "      <td>0.843750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Top-K  Accuracy\n",
       "0  Top-1  0.450893\n",
       "1  Top-2  0.649554\n",
       "2  Top-3  0.758929\n",
       "3  Top-4  0.808036\n",
       "4  Top-5  0.843750"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overall top-K accuracy\n",
    "Ks = [1, 2, 3, 4, 5]\n",
    "overall_acc = {}\n",
    "\n",
    "for k in Ks:\n",
    "    hit = 0\n",
    "    for i, row in df_results.iterrows():\n",
    "        found = False\n",
    "        for ki in range(1, k+1):\n",
    "            if row[f\"Top{ki}_Label\"] == row[\"True Label\"]:\n",
    "                found = True\n",
    "                break\n",
    "        if found:\n",
    "            hit += 1\n",
    "    overall_acc[f\"Top-{k}\"] = hit / len(df_results)\n",
    "\n",
    "overall_acc_df = pd.DataFrame(list(overall_acc.items()), columns=[\"Top-K\", \"Accuracy\"])\n",
    "overall_acc_df.to_csv(\"rs/zeroshotRS/overall_top5_accuracy.csv\", index=False)\n",
    "overall_acc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd1532a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Top-1 Acc</th>\n",
       "      <th>Top-2 Acc</th>\n",
       "      <th>Top-3 Acc</th>\n",
       "      <th>Top-4 Acc</th>\n",
       "      <th>Top-5 Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>animal crossing</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bumpy road</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cross road</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cycle crossing</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dip</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Class  Top-1 Acc  Top-2 Acc  Top-3 Acc  Top-4 Acc  Top-5 Acc\n",
       "0  animal crossing        0.3        0.5        0.6        0.7        0.8\n",
       "1       bumpy road        0.0        0.0        0.4        0.7        0.9\n",
       "2       cross road        0.4        0.7        0.9        1.0        1.0\n",
       "3   cycle crossing        1.0        1.0        1.0        1.0        1.0\n",
       "4              dip        0.0        0.0        0.0        0.0        0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Per-class top-K accuracy\n",
    "per_class_acc = []\n",
    "\n",
    "for class_name in label_names:\n",
    "    row = [class_name]\n",
    "    mask = df_results[\"True Label\"] == class_name\n",
    "    df_sub = df_results[mask]\n",
    "    n = len(df_sub)\n",
    "    for k in Ks:\n",
    "        hit = 0\n",
    "        for _, r in df_sub.iterrows():\n",
    "            found = False\n",
    "            for ki in range(1, k+1):\n",
    "                if r[f\"Top{ki}_Label\"] == r[\"True Label\"]:\n",
    "                    found = True\n",
    "                    break\n",
    "            if found:\n",
    "                hit += 1\n",
    "        acc = hit / n if n > 0 else 0.0\n",
    "        row.append(acc)\n",
    "    per_class_acc.append(row)\n",
    "\n",
    "header = [\"Class\"] + [f\"Top-{k} Acc\" for k in Ks]\n",
    "df_per_class_acc = pd.DataFrame(per_class_acc, columns=header)\n",
    "df_per_class_acc.to_csv(\"rs/zeroshotRS/per_class_top5_accuracy.csv\", index=False)\n",
    "df_per_class_acc.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
